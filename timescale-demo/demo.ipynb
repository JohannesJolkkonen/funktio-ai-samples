{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import dotenv\n",
    "from psycopg2 import extras\n",
    "import timescale_vector.client as tsv_client\n",
    "import os\n",
    "import json \n",
    "import pandas as pd\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup Timescale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv.load_dotenv()\n",
    "\n",
    "# -- Timescale\n",
    "\n",
    "TIMESCALE_USER = os.getenv(\"TIMESCALE_USER\")\n",
    "TIMESCALE_PASSWORD = os.getenv(\"TIMESCALE_PASSWORD\")\n",
    "TIMESCALE_PORT = os.getenv(\"TIMESCALE_PORT\")\n",
    "TIMESCALE_HOST = os.getenv(\"TIMESCALE_HOST\")\n",
    "TIMESCALE_DB = os.getenv(\"TIMESCALE_DB\")\n",
    "CONNECTION = f\"postgres://{TIMESCALE_USER}:{TIMESCALE_PASSWORD}@{TIMESCALE_HOST}:{TIMESCALE_PORT}/{TIMESCALE_DB}\"\n",
    "\n",
    "conn = psycopg2.connect(CONNECTION, cursor_factory=extras.DictCursor)\n",
    "cur = conn.cursor()\n",
    "\n",
    "\n",
    "vec = tsv_client.Sync(\n",
    "    service_url=CONNECTION, table_name=\"fortune_100\", num_dimensions=1536\n",
    ")\n",
    "vec.create_tables()\n",
    "\n",
    "# -- OpenAI\n",
    "\n",
    "oai_client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load company data to Timescale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cur.execute(\"DROP TABLE IF EXISTS fortune_100\")\n",
    "# conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import uuid\n",
    "\n",
    "\n",
    "def get_embeddings(text: str) -> list[int]:\n",
    "    return (\n",
    "        oai_client.embeddings.create(model=\"text-embedding-ada-002\", input=text)\n",
    "        .data[0]\n",
    "        .embedding\n",
    "    )\n",
    "\n",
    "\n",
    "def prepare_data_for_timescaledb(df: pd.DataFrame) -> list[tuple]:\n",
    "    \"\"\" \n",
    "    For the timescale_vector client, the data needs to be in the following schema:\n",
    "    - id is the UUID which uniquely identifies each vector.\n",
    "    - metadata is a JSONB column which stores the metadata associated with each vector.\n",
    "    - contents is the text column which stores the content we want vectorized (in this case the company description).\n",
    "    - embedding is the vector column which stores the vector embedding representation of the content.\n",
    "    \"\"\"\n",
    "    uuid_list = [\n",
    "        uuid.uuid5(uuid.NAMESPACE_DNS, row[\"company\"]) for i, row in df.iterrows()\n",
    "    ]\n",
    "    metadata_list = [\n",
    "        {k: v for k, v in row.items() if not pd.isnull(v) and k != \"description\"}\n",
    "        for i, row in df.iterrows()\n",
    "    ]\n",
    "    content_list = df[\"description\"].tolist()\n",
    "    embedding_list = [get_embeddings(description) for description in content_list]\n",
    "\n",
    "    # Create list of tuples/records\n",
    "    records = list(zip(uuid_list, metadata_list, content_list, embedding_list))\n",
    "    return records\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def read_csv(fpath: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(fpath)\n",
    "    df.columns = df.columns.str.replace(\" \", \"_\").str.lower()\n",
    "    df[\"market_cap\"] = df[\"market_cap\"].replace(\"-\", 0).astype(float)\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read_csv(\"data/fortune_100_with_descriptions.csv\")\n",
    "records = prepare_data_for_timescaledb(df)\n",
    "vec.upsert(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple Vector Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Robotics\"\n",
    "vec_query = get_embeddings(query)\n",
    "\n",
    "results = vec.search(query_embedding=vec_query, limit=4)\n",
    "for row in results:\n",
    "    print(row.get(\"metadata\").get(\"company\"))\n",
    "    print(row.get(\"contents\") + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add news & sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgcopy import CopyManager\n",
    "import eventregistry\n",
    "\n",
    "\n",
    "def get_company_news(company_name: str, n_results: int, lang: str = \"eng\") -> list[dict]:\n",
    "    \"\"\"\n",
    "    Get company news from Event Registry API\n",
    "    \"\"\"\n",
    "    er = eventregistry.EventRegistry(apiKey = os.getenv(\"EVENT_REGISTRY_API_KEY\"))\n",
    "    q = eventregistry.QueryArticlesIter(conceptUri = er.getConceptUri(company_name), keywords=company_name, keywordsLoc=\"title\", lang=[\"eng\"])\n",
    "    q.setRequestedResult(eventregistry.RequestArticlesInfo(count = n_results))\n",
    "    res = er.execQuery(q)\n",
    "    return res['articles']['results']\n",
    "\n",
    "\n",
    "def upload_news_to_timescaledb(news: list[dict], company_id: str):\n",
    "    for article in news:\n",
    "        cur.execute(\n",
    "            \"INSERT INTO news (company_id, title, body, url, published_at) VALUES (%s, %s, %s, %s, %s)\",\n",
    "            (\n",
    "                company_id,\n",
    "                article[\"title\"],\n",
    "                article[\"body\"],\n",
    "                article[\"url\"],\n",
    "                article[\"dateTimePub\"],\n",
    "            ),\n",
    "        )\n",
    "        conn.commit()\n",
    "\n",
    "\n",
    "def upload_sales_to_timescaledb(sales: pd.DataFrame):\n",
    "    with conn.cursor() as cur:\n",
    "        sales['date'] = pd.to_datetime(sales['date'])\n",
    "        data = list(sales.itertuples(index=False, name=None))\n",
    "        copy_manager = CopyManager(conn, \"sales\", [\"transaction_id\", \"company_id\", \"date\", \"amount\"])\n",
    "        try:\n",
    "            copy_manager.copy(data)\n",
    "        except ValueError as e:\n",
    "            print(f\"Error occurred: {e}\")\n",
    "        conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- Create news and sales tables\n",
    "cur.execute(\"DROP TABLE IF EXISTS sales\")\n",
    "cur.execute(\"DROP TABLE IF EXISTS news\")\n",
    "cur.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS news (id SERIAL PRIMARY KEY, company_id TEXT, title TEXT, body TEXT, url TEXT, published_at TIMESTAMP)\"\n",
    ")\n",
    "cur.execute(\n",
    "    \"CREATE TABLE IF NOT EXISTS sales (transaction_id TEXT, company_id TEXT, date TIMESTAMP, amount FLOAT)\"\n",
    ")\n",
    "conn.commit()\n",
    "\n",
    "# -- Fetch & upload news data\n",
    "\"\"\"\n",
    "You can also use the pre-loaded news in 'data/all_news.json', if you don't want to sign up for the event registry API. \n",
    "However, the news-json does not have a mapping to the companies. \n",
    "You could create this mapping by iterating over the companies, and matching them with news that contain the company name in the title.\n",
    "\"\"\"\n",
    "cur.execute(\"SELECT * FROM fortune_100\")\n",
    "rows = cur.fetchall()\n",
    "for i, row in enumerate(rows):\n",
    "    print(i)\n",
    "    company = (row.get('metadata').get('company'))\n",
    "    company_id = str(row.get('id'))\n",
    "    try:\n",
    "        news = get_company_news(company, n_results=5)\n",
    "        upload_news_to_timescaledb(news, company_id)\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching news for {company}: {e}\")\n",
    "\n",
    "# -- Upload sales data from csv\n",
    "\n",
    "sales_df = pd.read_csv(\"data/dummy_sales_transactions.csv\")\n",
    "upload_sales_to_timescaledb(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.rollback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, '73d5d45c-2547-580c-8421-e4819278af3a', 'Walmart $4 find makes car interior look brand new thanks to deep spring clean', 'DRIVERS are in the mood for a vehicle re-vamp after a TikToker showed them how their car can look brand new in just a few hours.\\n\\nWhile many people start spring cleaning their homes, TikTok users have been reminded not to forget their cars.\\n\\nNatalie Steinman (@nataliesteinman) showcased how she gets her vehicle looking brand new with some elbow grease, easy changes, and a little-known children\\'s toy that doubles as a cleaning product.\\n\\n\"Let the spring cleaning comments,\" Steinman told viewers in the caption of the video.\\n\\nSteinman focuses entirely on the interior of her car and starts by filling a trash bag full of receipts, empty bottles, and food wrappers.\\n\\nShe then removes the mats which she later cleans with soap and water and scrubs with a toilet brush.\\n\\nUsing a car hoover she then removes any crumbs and dirt from her Ford\\'s carpets and storage areas.\\n\\nThe TikToker then showed off the most ingenious cleaning hack using a children\\'s toy that can be bought at Walmart for less than $5.\\n\\nWhen it comes to cleaning cars, all drivers know the problem of getting dirt and dust out of various hard-to-reach areas like air vents.\\n\\nHowever, by using Silly Putty, Steinman can easily mold the slime into these problem areas.\\n\\nThis then picks up the dirt and removes it without leaving a mark.\\n\\nThe TikToker can be seen wiping the slime over her navigation and central console as well as the gear shift and inside cup holders.\\n\\nShe then uses wipes and screen cleaner to finish it all off, not forgetting the leather seats.\\n\\nOnce the mats are washed and have been dried with a leaf blower, they are placed back inside the vehicle and she adds a stylish car trash bag to the back and storage boxes in the trunk.\\n\\nFor moms and female drivers, the TikToker reminded them that a bag of essentials is always useful to keep in the car.\\n\\nSteinman fills a small cosmetics bag with tampons, lip gloss, Advil, perfume, and mascara which she then places on the armrest next to the driver.\\n\\nOther items that may be useful to store in the vehicle include tissues, wipes, small snacks, band-aids, a phone charger, and sanitary pads.\\n\\nAfter some hard work, Steinman rewarded herself with a new key cover for her fob which was the final touch to make the car look and feel brand new.\\n\\n\"Giving me the motivation,\" one viewer commented as others fell in love with the key cover from Amazon.\\n\\nOne tip includes how to do the Japanese door trick which does not involve any additional items but effectively displaces hot air and cools the interior.', 'https://www.the-sun.com/motors/10845977/drivers-rave-spring-car-cleaning-walmart-find/', datetime.datetime(2024, 3, 21, 9, 31), UUID('73d5d45c-2547-580c-8421-e4819278af3a'), {'ceo': 'C. Douglas McMillon', 'city': 'Bentonville', 'rank': 1, 'state': 'AR', 'profit': 13673.0, 'sector': 'Retailing', 'ticker': 'WMT', 'company': 'Walmart', 'revenue': 572754.0, 'website': 'https://www.stock.walmart.com', 'newcomer': 'no', 'ceo_woman': 'no', 'prev_rank': 1, 'market_cap': 352037.0, 'profitable': 'yes', 'ceo_founder': 'no', 'rank_change': 0, 'num_of_employees': 2300000}, \"Walmart is a multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores. It is one of the world's largest companies by revenue and employs millions of people globally. Walmart is known for its wide range of products at competitive prices, offering everything from groceries and household goods to electronics and clothing. With its online presence and extensive network of physical stores, Walmart serves millions of customers every day, making it a key player in the retail industry.\", array([-0.01200807, -0.00707811, -0.00499333, ..., -0.00989794,\n",
      "       -0.0098219 , -0.00128952], dtype=float32)]\n",
      "[2, '73d5d45c-2547-580c-8421-e4819278af3a', 'Police searching for man, woman after incident at a Canton Walmart', 'Holly Springs Police Department is asking you to be on the lookout for two suspects.\\n\\nPolice said the man and woman pictured are persons of interest in an open investigation.\\n\\n[DOWNLOAD: Free WSB-TV News app for alerts as news breaks]\\n\\nPolice said the incident happened at the Wal-Mart on Holly Springs Parkway in Canton.\\n\\nAt this time, details on why the suspects are wanted have not been shared by police.\\n\\nPolice provided a photo of the vehicle they drove away in.\\n\\nTRENDING STORIES:\\n\\nIf you have any information on either of the suspects, please contact The Holly Springs Police Department.', 'https://www.yahoo.com/news/police-searching-man-woman-incident-035624244.html', datetime.datetime(2024, 3, 21, 5, 18, 49), UUID('73d5d45c-2547-580c-8421-e4819278af3a'), {'ceo': 'C. Douglas McMillon', 'city': 'Bentonville', 'rank': 1, 'state': 'AR', 'profit': 13673.0, 'sector': 'Retailing', 'ticker': 'WMT', 'company': 'Walmart', 'revenue': 572754.0, 'website': 'https://www.stock.walmart.com', 'newcomer': 'no', 'ceo_woman': 'no', 'prev_rank': 1, 'market_cap': 352037.0, 'profitable': 'yes', 'ceo_founder': 'no', 'rank_change': 0, 'num_of_employees': 2300000}, \"Walmart is a multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores. It is one of the world's largest companies by revenue and employs millions of people globally. Walmart is known for its wide range of products at competitive prices, offering everything from groceries and household goods to electronics and clothing. With its online presence and extensive network of physical stores, Walmart serves millions of customers every day, making it a key player in the retail industry.\", array([-0.01200807, -0.00707811, -0.00499333, ..., -0.00989794,\n",
      "       -0.0098219 , -0.00128952], dtype=float32)]\n",
      "[3, '73d5d45c-2547-580c-8421-e4819278af3a', 'How media buyers view the retail media landscape  --  from Amazon to Walmart to Wawa', 'The promise of wealth, or in this case, ad dollars, has the marketplace heating up with scads of retailers, from first-movers like Amazon to newcomers like Wawa convenience store -- even to the unsuspected like Cars.com automotive company.\\n\\nBy the end of this year, retail media ad spend is expected to make up one-fifth of worldwide digital ad spend, scooping up $140 billion, which is up from the forecasted $115 billion in 2023, according to eMarketer.\\n\\nRetail media is a growing space, no doubt. Especially as advertisers are eager to plug the holes Google\\'s third-party cookie deprecation is leaving behind. But that growth has led to fragmentation as agencies grapple with where to spend client ad dollars that\\'ll give the most bang for their buck.\\n\\n\"From where we sit as an agency, it\\'s certainly making our lives and our day-to-day work more exciting, more challenging,\" said Ethan Goodman, evp of digital commerce at The Mars Agency.\\n\\nIn regards to the biggest players in the space, like Amazon Ads, Roundel (Target\\'s retail media business), Walmart Connect and Albertsons Media Collective, he said, \"They have significantly improved and scaled their capabilities -- their audience and targeting capabilities, their measurement capabilities. Really practically, they\\'ve improved their channel offering and the breadth of their channel capabilities.\"\\n\\nDigiday caught up with Goodman and other agency executives to talk about how the retail media competition is looking -- and the players most on their radar.\\n\\nAmazon Advertising launched in 2012, giving it a first-mover advantage in the space and making it almost synonymous with the concept of retail media. This year, Amazon is expected to hoover up 74% of the nearly $60 billion in U.S. digital retail media ad spend, according to eMarketer\\'s forecasts. Given its pure scale, Amazon could stand as an unexpected beneficiary of Google Chrome\\'s third-party cookie fallout once the dust settles.\\n\\nAs its business matures, the mammoth-sized company has made recent ad tech and artificial intelligence upgrades to enhance its offering as well as new inventory, selling ads on Prime Video to advertisers. This layers on top of its self-service ad solution through its owned streaming services like Freevee, Twitch and Thursday Night Football, and in-store advertising through Whole Foods Market and Amazon Fresh, making it a top contender for ad dollars.\\n\\n\"A lot of our brand national dollars are spent across Amazon,\" said an agency executive who spoke with Digiday and requested anonymity. The exec did not disclose spend figures. \"As CPG becomes more important for Amazon and grocery becomes a bigger deal for them, whether that\\'s through Whole Foods or Amazon Fresh or other places, we\\'re going to see our CPG spend continue to increase.\"\\n\\nBeyond its sheer size (it touts an audience of more than 150 million), Amazon\\'s ad business is an ecosystem with data from Amazon DSP, Amazon Ads APIs and Amazon Marketing Cloud, offering marketers more granular audience insights. Amazon also opened its platform to developers and plug-ins for things like dashboards or other tools.\\n\\n\"They\\'re able to do closed loop attribution, whereby the performance of an impression served on Amazon Prime can be tracked back to what it ultimately helps drive at the Amazon.com level,\" said Harry Inglis, head of activation at Media by Mother, Mother\\'s three-year-old media agency. \"It\\'s hard to compete with.\"\\n\\nAnother early entrant to the retail media competition, Walmart Connect, has moved recently to close the gap between it and Amazon. In February, Walmart announced plans to acquire smart TV manufacturer Vizio for $2.3 billion, bolstering its retail media offering by adding more streaming capabilities. In January, it set its sights on a TikTok integration, offering advertisers sales measurement data and access to the coveted Gen Z audience. Both of these events build on its partnership with Roku, announced in 2022, to bring shoppable ads to streaming. And it helps that Walmart has a massive physical presence with more than 4,600 locations in the U.S., shadowing Amazon\\'s 500 Whole Foods Markets.\\n\\nHaving launched back in 2017, Walmart Connect has spent the last year-and-a-half beefing up its advertising capabilities, including the Walmart Connect Academy Ad Certification program to educate agencies and brands on what it can do. Its latest move with Vizio, and now integration with TikTok, is intended to reach advertisers\\' latest fascination: streaming and digital video.\\n\\n\"The more that they\\'re moving those digital solutions in-store, I think will be some of the growth,\" the anonymous agency exec told Digiday. \"[RMNs] already made partnerships and social, which was smart because that\\'s where people are spending a lot of their time. And then, now where? Now, it\\'s streaming?\"\\n\\nSpending on platforms outside of Amazon, like Walmart, Target and the like, is seeing double-digit growth this year. Notably, Walmart appears to be at the helm of said growth spurt, according to previous Digiday reporting.\\n\\nThe U.S. Federal Trade Commission\\'s decision to block the Kroger-Albertsons merger last month may have put a wrench in growth plans, but Albertsons Media Collective is still one of the top contenders for retail media network spend -- a tertiary challenger, behind the likes of Amazon, Walmart, Target and of course, Kroger, agency execs say.\\n\\nIt only launched back in 2022, but has sparked advertisers\\' interest, noted as a more ambitious player in the space, listening to both needs and wants in the marketplace, per agency execs. Last January, Albertsons became the first advertiser to use LiveRamp and Pinterest\\'s clean room offering to tie offline sales to online behavior.\\n\\nBut perhaps most notably, the grocery chain has started aiming to tackle standardization and measurement issues, a pain point in an increasingly crowded and fragmented marketplace. And that\\'s what sets it apart, per agency execs.\\n\\n\"Albertsons actually came out publicly and are talking all about measurement and standardization,\" said a second agency exec who wished to remain anonymous. \"They\\'re really trying to set the standards, be the retailer that\\'s leaning into these standards.\"\\n\\nIn a sea of retail media networks, agency executives highlighted The Home Depot\\'s unique data as a keen proposition to advertisers. The retailer offers on-site and off-site ad placements and is able to create audiences around specific groups, including people who have recently moved, those who are redecorating, or setting up a business or any other life event. Each of these data points can win over a range of advertisers, whether it be internet providers or insurance companies.\\n\\nThe niche nature of The Home Depot, which launched its offering in 2019, gives it a competitive edge for some executives. Instead of identifiers like demographics or psychographic data, The Home Depot builds audiences based on home projects shoppers are doing -- a data point not easily found within the retail media space, especially at that scale. Notably, the company has more than 2,300 stores across North America.\\n\\n\"Home Depot, they actually have something unique in the sense of they created the retail media plus network,\" said the second agency exec. \"From that capacity, they are trying to not only sell media to their suppliers, but ask their suppliers what they want.\"\\n\\nIn a recent interview with Digiday, Melanie Babcock, vp of Retail Media+ and monetization at The Home Depot, said the company is looking to expand beyond endemic advertisers.\\n\\nInstacart exploded during the pandemic lockdown, when shoppers turned to the delivery service to shop at grocery stores and convenience stores without leaving the comfort of their home.\\n\\nIn a post-Covid world, agency execs wondered if Instacart would continue to thrive and if it would gobble up ad dollars via its retail media network, which launched in 2022.\\n\\n\"We were questioning whether it was true incrementality because a lot of what they were delivering was retailers that we already had agreements with. They were just the delivery platform at the time,\" said the first agency executive. Thus far, they said, it\\'s held up.\\n\\nThis year, the company started looking at off-site retail media, pitching advertisers on Google Shopping ads, which are enhanced by its own retail media data. As Retail Dive recently reported in January, early advertisers for the move include Danone\\'s Oikos and Kraft Heinz\\'s Kraft.\\n\\nThat partnership has sparked advertisers\\' interest as the company\\'s retail partners are making placements available on their shopping cart, an interesting proposition for consumer packaged goods brands, the exec said.\\n\\nOther off-site efforts include a partnership with Roku last April, and ad targeting on Sprouts Farmers Market last May.\\n\\nWith seven years in the retail media network game, Kroger Precision Marketing (KPM) has made a name for itself, partnering with the likes of Cooler Screens, Meta, Pinterest, Roku, Snap, The Trade Desk and others.\\n\\nLike Albertsons, the U.S. Federal Trade Commission\\'s decision to block the Kroger-Albertsons merger may have put a damper on growth. But with recent innovations, growth is expected to continue. The retailer has been steadily growing its ad offering, with efforts to marry online and offline sales data dating back to 2020.\\n\\nLast November, KPM announced new programmatic capabilities with The Trade Desk. Last June, Kroger took its self-service ad platform in-house, giving advertisers access to the grocer\\'s product listing ads as well as display advertising.\\n\\n\"Kroger is one of the top offerings in the U.S.,\" said the second agency executive. \"We think the best data offerings to date. However, they are extremely conservative when it comes to making any type of decisions (innovations, legal, negotiations etc.).\" Again, this is in comparison to retailers like Albertsons, which the agency exec says is more ambitious when it comes to responding to an ever-changing marketplace.\\n\\nKroger may have more red tape, but it has spent the last year-and-a-half shifting to a \"mindset of collaboration,\" according to the first agency executive. The retailer has also started to focus on things like standardization and measurement. All in all, Kroger is considered a top partner for the agency, who said Kroger\\'s offering is on par with Walmart.\\n\\nTarget has been aiming to build a media business to rival Amazon since rebranding as Roundel in 2019. Seemingly, it\\'s making good on its promise, coming in at marketers\\' third most-used retail media network, according to Digiday research, behind Amazon and Walmart.\\n\\nLast October, Target announced that it was enhancing its Roundel retail media business with Roundel Media Studio, a self-service buying tool, premium programmatic publisher partners and experimenting with shoppable connected TV. Roundel has recently been focused on expanding both its onsite and offsite inventory, including new ad formats like shoppable CTV, according to The Mars Agency\\'s Retail Media Report Card, a quarterly assessment and comparison retail media platform comparison tool.\\n\\nIt all makes a compelling argument as far as advertisers are concerned. Meaning Roundel is considered one of the leaders in the retail media landscape, given the retailer\\'s capabilities around audiences, channels and measurement. \"They are also notably ahead of the game when it comes to taking an integrated approach to media and merchandising, and creating both seamless omnichannel experiences for Target guests and holistic, added-value opportunities for brands/advertisers,\" said a third agency exec, who spoke anonymously.\\n\\nWawa convenience store is the latest to throw its hat in the ring as a retail media network competitor. While having only launched weeks ago, agency executives say clients are already interested in its offerings, especially in its fuel pump screen inventory.\\n\\nThe convenience store partnered with Publicis Groupe\\'s Publicis Sapient, Epsilon, and CitrusAd for its offering, with custom ads and campaigns on digital channels like Wawa\\'s websites, mobile app or video ads at a Wawa pump -- a selling point for advertisers looking for more ways to get in front of shoppers.\\n\\n\"In addition to allowing brands to reach their shoppers on their website and inside their mobile app, they\\'re also making some of their gas station screen inventory available,\" said Goodman. \"Some of those unique inventory opportunities are again, a potential point of differentiation for players like that.\"\\n\\nOther selling points are Wawa\\'s audience, which could be unique given it has a cult-like following, and its ability to close the loop from customers seeing an ad at the pump before going into the convenience store to make a purchase. Given, the convenience store chain is smaller with about 1,000 locations in Pennsylvania, New Jersey and Florida. This year, the convenience store opened its first Georgia location.\\n\\n\"For a challenger like Wawa to go out to the brand marketplace and say, \\'I can uniquely reach this audience segment that you can\\'t reach through another retail media network,\\' is a potential way in and is an advantage for them for sure,\" per Goodman.', 'https://digiday.com/marketing/how-media-buyers-view-the-retail-media-landscape-from-amazon-to-walmart-to-wawa/', datetime.datetime(2024, 3, 21, 4, 2, 42), UUID('73d5d45c-2547-580c-8421-e4819278af3a'), {'ceo': 'C. Douglas McMillon', 'city': 'Bentonville', 'rank': 1, 'state': 'AR', 'profit': 13673.0, 'sector': 'Retailing', 'ticker': 'WMT', 'company': 'Walmart', 'revenue': 572754.0, 'website': 'https://www.stock.walmart.com', 'newcomer': 'no', 'ceo_woman': 'no', 'prev_rank': 1, 'market_cap': 352037.0, 'profitable': 'yes', 'ceo_founder': 'no', 'rank_change': 0, 'num_of_employees': 2300000}, \"Walmart is a multinational retail corporation that operates a chain of hypermarkets, discount department stores, and grocery stores. It is one of the world's largest companies by revenue and employs millions of people globally. Walmart is known for its wide range of products at competitive prices, offering everything from groceries and household goods to electronics and clothing. With its online presence and extensive network of physical stores, Walmart serves millions of customers every day, making it a key player in the retail industry.\", array([-0.01200807, -0.00707811, -0.00499333, ..., -0.00989794,\n",
      "       -0.0098219 , -0.00128952], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "cur.execute(\"\"\"\n",
    "    SELECT * \n",
    "    FROM news \n",
    "    JOIN (\n",
    "            SELECT * from fortune_100 \n",
    "            WHERE metadata->>'company' = 'Walmart'\n",
    "        ) AS walmart\n",
    "    ON news.company_id = walmart.id::text\n",
    "\"\"\"\n",
    ")\n",
    "news_data = cur.fetchall()\n",
    "for row in news_data:\n",
    "    print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combined vector + relational queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple: 273503.0$\n",
      "Intel: 247760.0$\n",
      "Alphabet: 248683.0$\n"
     ]
    }
   ],
   "source": [
    "# -- Get result for vector search\n",
    "\n",
    "vec_query = get_embeddings(\"Smartphones, design\")\n",
    "# vec_results = vec.search(query_embedding=vec_query, limit=3)\n",
    "vec_results = vec.search(\n",
    "    query_embedding=vec_query, limit=3, \n",
    "    filter={\"state\": \"CA\"}, \n",
    "    predicates=tsv_client.Predicates(\"num_of_employees\", \">\", 100000)\n",
    ")\n",
    "\n",
    "\n",
    "# -- Get related sales data\n",
    "for result in vec_results:\n",
    "    id = result.get('id')\n",
    "    cur.execute(f\"SELECT SUM(amount) FROM sales WHERE company_id = '{id}'\")\n",
    "    sales = cur.fetchall()[0][0]\n",
    "    print(f\"{result.get('metadata').get('company')}: {sales}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct queries from natural language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import instructor\n",
    "import enum\n",
    "from typing import List\n",
    "from pydantic import Field, BaseModel\n",
    "from datetime import date\n",
    "import json \n",
    "from timescale_vector import client as tsv_client\n",
    "\n",
    "\n",
    "vec = tsv_client.Sync(\n",
    "    service_url=CONNECTION, table_name=\"fortune_100\", num_dimensions=1536\n",
    ")\n",
    "\n",
    "oai_client = OpenAI()\n",
    "\n",
    "client = instructor.patch(oai_client)\n",
    "\n",
    "query_planner_prompt = f\"\"\"\n",
    "You are a world class query planning algorithm capable of breaking apart questions into its dependency queries,\n",
    "such that the answers can be used to inform the parent question. \n",
    "1. The queries should be of three types, depending on what is searched: \"COMPANY\", \"SALES\" or \"NEWS\".\n",
    "2. Before running SALES or NEWS queries, we first need a company for which we are finding sales/news for. \n",
    "3. Determine parameters to be passed to each query. \n",
    "    3.1 for COMPANY-queries, determine an appropriate 'keywords'-parameter, which is list of keywords that can be used for finding the company. Where applicable, return also a 'filter'-parameter, in the format of [{{'field':'value'}},..]. Filters can be applied to the following fields: 'state', a two-letter state code, or 'city', the company's city. For example, {{'state':'NY'}}\n",
    "    3.2 for NEWS- and SALES-queries, determine an optional daterange if specified, with parameters 'min_date' and 'max_date'. The current date is {date.today()}.\n",
    "4. Do not answer the questions, simply provide a correct compute graph with good specific questions to ask and relevant dependencies. \n",
    "5. Before you call the function, think step-by-step to get a better understanding of the problem.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class QueryType(str, enum.Enum):\n",
    "    \"\"\"Enumeration representing the types of queries that can be made to our database\"\"\"\n",
    "\n",
    "    COMPANY_SEARCH = \"COMPANY\"\n",
    "    NEWS_SEARCH = \"NEWS\"\n",
    "    SALES_SEARCH = \"SALES\"\n",
    "\n",
    "\n",
    "class Query(BaseModel):\n",
    "    \"\"\"Class representing a single query in a query plan.\"\"\"\n",
    "\n",
    "    id: int = Field(..., description=\"Unique ID of the query\")\n",
    "\n",
    "    parameters: dict = Field(\n",
    "        ..., description=\"The parameters to be passed to the query\"\n",
    "    )\n",
    "\n",
    "    dependencies: List[int] = Field(\n",
    "        description=\"List of IDs of queries that need to be answered before this query\"\n",
    "    )\n",
    "\n",
    "    query_type: QueryType = Field(\n",
    "        description=\"Type of query, either a vector query, news query or sales query\"\n",
    "    )\n",
    "\n",
    "    def run(self) -> list[tuple]:\n",
    "        \"\"\"Runs a query depending on the query_type\"\"\"\n",
    "        if self.query_type == QueryType.COMPANY_SEARCH:\n",
    "            vector_query = get_embeddings(self.parameters.get(\"keywords\"))\n",
    "            filters = self.parameters.get(\"filter\")\n",
    "            results = vec.search(vector_query, limit=3, filter=filters)\n",
    "            return [(r.get('metadata').get('company'), str(r.get('id'))) for r in results]\n",
    "\n",
    "        elif self.query_type == QueryType.SALES_SEARCH:\n",
    "            query = f\"SELECT SUM(amount) FROM sales WHERE company_id = '{self.parameters.get('company_id')}'\"\n",
    "            if \"min_date\" in self.parameters and \"max_date\" in self.parameters:\n",
    "                query += f\" AND date BETWEEN '{self.parameters.get('min_date')}' AND '{self.parameters.get('max_date')}'\"\n",
    "            elif \"min_date\" in self.parameters:\n",
    "                query += f\" AND date >= '{self.parameters.get('min_date')}'\"\n",
    "            elif \"max_date\" in self.parameters:\n",
    "                query += f\" AND date <= '{self.parameters.get('max_date')}'\"\n",
    "            cur.execute(query)\n",
    "            results = cur.fetchall()\n",
    "            return results\n",
    "\n",
    "        elif self.query_type == QueryType.NEWS_SEARCH:\n",
    "            query = f\"SELECT title FROM news WHERE company_id = '{self.parameters.get('company_id')}'\"\n",
    "            if \"min_date\" in self.parameters and \"max_date\" in self.parameters:\n",
    "                query += f\" AND published_at BETWEEN '{self.parameters.get('min_date')}' AND '{self.parameters.get('max_date')}'\"\n",
    "            elif \"min_date\" in self.parameters:\n",
    "                query += f\" AND published_at >= '{self.parameters.get('min_date')}'\"\n",
    "            elif \"max_date\" in self.parameters:\n",
    "                query += f\" AND published_at <= '{self.parameters.get('max_date')}'\"\n",
    "\n",
    "            cur.execute(query)\n",
    "            results = cur.fetchall()\n",
    "            return [r.get('title') for r in results]\n",
    "\n",
    "\n",
    "class QueryPlan(BaseModel):\n",
    "    \"\"\"Container class representing a tree of queries to run against a database, to answer a user's question\"\"\"\n",
    "\n",
    "    query_plan: List[Query] = Field(\n",
    "        ..., description=\"The query plan representing the queries to run\"\n",
    "    )\n",
    "\n",
    "    def execute(self):\n",
    "        # Dict to store results from all queries\n",
    "        results = {}\n",
    "\n",
    "        # Execute the queries in the order of their dependencies\n",
    "        for query in self.query_plan:\n",
    "            print(f\"Running query {query.id}: {query.query_type.name}\")\n",
    "            if not query.dependencies:\n",
    "                results[query.query_type] = query.run()\n",
    "                company_ids = [r[1] for r in results[query.query_type]]\n",
    "            else:\n",
    "                # Then execute the query for all companies returned by dependency\n",
    "                all_results = []\n",
    "                for id in company_ids:\n",
    "                    query.parameters['company_id'] = id\n",
    "                    all_results.append(query.run())\n",
    "                results[query.query_type] = all_results\n",
    "        \n",
    "        return results\n",
    "        \n",
    "\n",
    "def query_planner(question: str) -> QueryPlan:\n",
    "    PLANNING_MODEL = \"gpt-4-0613\"\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": query_planner_prompt},\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Consider: {question}\\n Generate the correct query plan.\",\n",
    "        },\n",
    "    ]\n",
    "    plan = client.chat.completions.create(\n",
    "        model=PLANNING_MODEL,\n",
    "        response_model=QueryPlan,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "    )\n",
    "    return plan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query_plan': [{'id': 1,\n",
       "   'parameters': {'keywords': ['AI'], 'filter': [{'state': 'CA'}]},\n",
       "   'dependencies': [],\n",
       "   'query_type': <QueryType.COMPANY_SEARCH: 'COMPANY'>},\n",
       "  {'id': 2,\n",
       "   'parameters': {'min_date': '2024-03-15', 'max_date': '2024-03-22'},\n",
       "   'dependencies': [1],\n",
       "   'query_type': <QueryType.NEWS_SEARCH: 'NEWS'>},\n",
       "  {'id': 3,\n",
       "   'parameters': {'min_date': '2024-02-22', 'max_date': '2024-03-22'},\n",
       "   'dependencies': [1],\n",
       "   'query_type': <QueryType.SALES_SEARCH: 'SALES'>}]}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"Get me AI companies in California, and last weeks news related to them, and last months sales for each\"\n",
    "plan = query_planner(question)\n",
    "plan.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running query 1: COMPANY_SEARCH\n",
      "Running query 2: NEWS_SEARCH\n",
      "Running query 3: SALES_SEARCH\n",
      "Companies:\n",
      "('Apple', '33a3f638-20dc-5797-a9e2-660ae1bad782')\n",
      "('Intel', '390293f2-6297-554c-8a51-93d478191795')\n",
      "('Alphabet', '73b37e59-1e24-5e0b-afbf-e84263089fbe')\n",
      "News:\n",
      "[\"Tech giants show Epic support against Apple's payment rules\", \"The 30 Best Tech Deals in Amazon's Big Spring Sale  --  Including Apple, Beats, Dyson, and More Up to 77% Off\", 'Meta, Microsoft slam Apple over app store policy']\n",
      "['Intel Gets $20Bn From CHIPS Fund, Plans To Invest $100Bn In US', 'Intel To Receive Up To $8.5 Billion In CHIPS Act Grants As US Speeds Up Semiconductor Manufacturing Drive', 'Intel To Receive Up To $8.5 Billion In CHIPS Act Grants As US Speeds Up Semiconductor Manufacturing Drive']\n",
      "['Is Alphabet (GOOG) Stock Trading at a Reasonable Valuation?', 'Alphabet Inc CEO Sundar Pichai Sells 22,500 Shares', \"Gene Munster Agrees With Dan Nathan's Views That These 2 Magnificent 7 Companies Are AI Underdogs: 'I Believe That Will Change' - Alphabet (NASDAQ:GOOG), Apple (NASDAQ:AAPL)\"]\n",
      "Sales:\n",
      "[[88268.0]]\n",
      "[[90357.0]]\n",
      "[[71225.0]]\n"
     ]
    }
   ],
   "source": [
    "results = plan.execute()\n",
    "\n",
    "for k, v in results.items():\n",
    "    if k == QueryType.COMPANY_SEARCH:\n",
    "        print(\"Companies:\")\n",
    "    if k == QueryType.SALES_SEARCH:\n",
    "        print(\"Sales:\")\n",
    "    if k == QueryType.NEWS_SEARCH:\n",
    "        print(\"News:\")\n",
    "    for val in v:\n",
    "        print(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are some AI companies in California, recent news related to them, and their sales for the last month:\n",
      "\n",
      "1. Apple:\n",
      "   - News: \n",
      "     - \"Tech giants show Epic support against Apple's payment rules\"\n",
      "     - \"The 30 Best Tech Deals in Amazon's Big Spring Sale  --  Including Apple, Beats, Dyson, and More Up to 77% Off\"\n",
      "     - \"Meta, Microsoft slam Apple over app store policy\"\n",
      "   - Sales for last month: $88,268.0 million\n",
      "\n",
      "2. Intel:\n",
      "   - News: \n",
      "     - \"Intel Gets $20Bn From CHIPS Fund, Plans To Invest $100Bn In US\"\n",
      "     - \"Intel To Receive Up To $8.5 Billion In CHIPS Act Grants As US Speeds Up Semiconductor Manufacturing Drive\"\n",
      "   - Sales for last month: $90,357.0 million\n",
      "\n",
      "3. Alphabet:\n",
      "   - News: \n",
      "     - \"Is Alphabet (GOOG) Stock Trading at a Reasonable Valuation?\"\n",
      "     - \"Alphabet Inc CEO Sundar Pichai Sells 22,500 Shares\"\n",
      "     - \"Gene Munster Agrees With Dan Nathan's Views That These 2 Magnificent 7 Companies Are AI Underdogs: 'I Believe That Will Change' - Alphabet (NASDAQ:GOOG), Apple (NASDAQ:AAPL)\"\n",
      "   - Sales for last month: $71,225.0 million\n"
     ]
    }
   ],
   "source": [
    "answer_prompt = \"\"\"\n",
    "You will respond to a user's question, based on the results of several queries.\n",
    "\"\"\"\n",
    "def generate_answer(question, results):\n",
    "    answer = client.chat.completions.create(\n",
    "        model=\"gpt-4-0613\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": answer_prompt},\n",
    "            {\"role\": \"user\", \"content\": f\"User question: {question}\\n Query results: {results}\"},\n",
    "        ],\n",
    "        temperature=0,\n",
    "        max_tokens=1000,\n",
    "    ).choices[0].message.content\n",
    "    return answer\n",
    "\n",
    "a = generate_answer(\"Get me AI companies in California, and last weeks news related to them, and also get sales for last month for each\", results)\n",
    "print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "plan_json = \"\"\"{\n",
    "    \"query_plan\": [\n",
    "        {\n",
    "            \"id\": 1,\n",
    "            \"parameters\": {\n",
    "                \"keywords\": [\n",
    "                    \"insurance\",\n",
    "                    \"clients\"\n",
    "                ]\n",
    "            },\n",
    "            \"dependencies\": [],\n",
    "            \"query_type\": \"COMPANY\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 2,\n",
    "            \"parameters\": {\n",
    "                \"min_date\": \"2024-02-18\",\n",
    "                \"max_date\": \"2024-03-20\"\n",
    "            },\n",
    "            \"dependencies\": [\n",
    "                1\n",
    "            ],\n",
    "            \"query_type\": \"SALES\"\n",
    "        },\n",
    "        {\n",
    "            \"id\": 3,\n",
    "            \"parameters\": {\n",
    "                \"min_date\": \"2024-03-13\",\n",
    "                \"max_date\": \"2024-03-20\"\n",
    "            },\n",
    "            \"dependencies\": [\n",
    "                1\n",
    "            ],\n",
    "            \"query_type\": \"NEWS\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\"\"\"\n",
    "# plan_json = \"\"\"{\n",
    "#     \"query_plan\": [\n",
    "#         {\n",
    "#             \"id\": 1,\n",
    "#             \"parameters\": {\n",
    "#                 \"keywords\": [\n",
    "#                     \"insurance\",\n",
    "#                     \"clients\"\n",
    "#                 ]\n",
    "#             },\n",
    "#             \"dependencies\": [],\n",
    "#             \"query_type\": \"COMPANY\"\n",
    "#         }\n",
    "#     ]\n",
    "# }\n",
    "# \"\"\"\n",
    "plan = QueryPlan.parse_raw(plan_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Stashed code, using sql instead of the tsv_client\"\"\"\n",
    "# import uuid\n",
    "\n",
    "# cur.execute(\"CREATE EXTENSION IF NOT EXISTS vector\")\n",
    "# conn.commit()\n",
    "\n",
    "\n",
    "# def create_company_table():\n",
    "#     create_table_query = \"\"\"\n",
    "#     DROP TABLE IF EXISTS fortune_100;\n",
    "#     CREATE TABLE fortune_100 (\n",
    "#         company TEXT,\n",
    "#         rank FLOAT,\n",
    "#         rank_change FLOAT,\n",
    "#         revenue FLOAT,\n",
    "#         profit FLOAT,\n",
    "#         num_of_employees FLOAT,\n",
    "#         sector TEXT,\n",
    "#         city TEXT,\n",
    "#         state TEXT,\n",
    "#         newcomer BOOLEAN,\n",
    "#         ceo_founder BOOLEAN,\n",
    "#         ceo_woman BOOLEAN,\n",
    "#         profitable BOOLEAN,\n",
    "#         prev_rank FLOAT,\n",
    "#         ceo TEXT,\n",
    "#         website TEXT,\n",
    "#         ticker TEXT,\n",
    "#         market_cap FLOAT,\n",
    "#         description TEXT,\n",
    "#         embeddings vector(1536)\n",
    "#     );\n",
    "#     \"\"\"\n",
    "#     cur.execute(create_table_query)\n",
    "#     conn.commit()\n",
    "\n",
    "\n",
    "# def prepare_data_for_timescaledb(df: pd.DataFrame) -> list[tuple]:\n",
    "#     uuid_list = [uuid.uuid4() for _ in range(len(df))]\n",
    "#     metadata_list = [\n",
    "#         {k: v for k, v in row.items() if not pd.isnull(v) and k != \"description\"}\n",
    "#         for i, row in df.iterrows()\n",
    "#     ]\n",
    "#     content_list = df[\"description\"].tolist()\n",
    "#     embedding_list = [get_embeddings(description) for description in content_list]\n",
    "\n",
    "#     # Create list of tuples/records\n",
    "#     records = list(zip(uuid_list, metadata_list, content_list, embedding_list))\n",
    "#     return records\n",
    "\n",
    "\n",
    "# def load_csv_to_timescaledb(csv_file_path, table_name):\n",
    "#     df = pd.read_csv(csv_file_path)\n",
    "#     cols = df.columns\n",
    "#     cols = [col.replace(\" \", \"_\").lower() for col in cols]\n",
    "#     # cur.execute(f\"ALTER TABLE {table_name} ADD COLUMN IF NOT EXISTS embedding vector(1536)\")\n",
    "#     df.columns = df.columns.str.replace(\" \", \"_\").str.lower()\n",
    "#     df[\"market_cap\"] = df[\"market_cap\"].replace(\"-\", 0).astype(float)\n",
    "#     # Use iterative inserts to efficiently copy data from the CSV to the TimescaleDB table\n",
    "#     for i, row in df.iterrows():\n",
    "#         filtered_values = tuple(row[col] for col in cols)\n",
    "#         try:\n",
    "#             cur.execute(\n",
    "#                 f\"INSERT INTO {table_name} ({', '.join(cols)}) VALUES ({', '.join(['%s' for _ in cols])})\",\n",
    "#                 filtered_values,\n",
    "#             )\n",
    "#         except Exception as e:\n",
    "#             print(f\"Exception: {e}\")\n",
    "#             print(filtered_values)\n",
    "#             print(\n",
    "#                 f\"INSERT INTO {table_name} ({', '.join(cols)}) VALUES ({', '.join(['%s' for _ in cols])})\",\n",
    "#                 filtered_values,\n",
    "#             )\n",
    "\n",
    "#     conn.commit()\n",
    "\n",
    "\n",
    "# # create_company_table()\n",
    "# # load_csv_to_timescaledb(\"fortune_100_with_embeddings.csv\", \"fortune_100\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = plan.execute()\n",
    "\n",
    "def parse_results(results:dict):\n",
    "    for k, v in results.items():\n",
    "        if k == QueryType.COMPANY_SEARCH:\n",
    "            print(\"Companies:\")\n",
    "            company_results = v\n",
    "        if k == QueryType.SALES_SEARCH:\n",
    "            print(\"Sales:\")\n",
    "            sales_results = v\n",
    "        if k == QueryType.NEWS_SEARCH:\n",
    "            print(\"News:\")\n",
    "            news_results = v\n",
    "        for val in v:\n",
    "            print(val)\n",
    "    return list(zip(company_results,sales_results,news_results))\n",
    "\n",
    "parsed_results = parse_results(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
